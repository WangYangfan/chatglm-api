import random
import os
import numpy as np
import torch
import json
import requests

def seed_environment(seed):
    """ è®¾ç½®æ•´ä¸ªç¯å¢ƒçš„éšæœºç§å­ """
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    return

def torch_gc(device):
    if torch.cuda.is_available():
        with torch.cuda.device(device):
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()

def gen_response(query, history=[], max_length=None, top_p=None, temperature=None):
    # å¦‚æœæƒ³è¿ç»­è¯¢é—®ï¼Œåº”è¡¥å……historyï¼Œhistoryæ˜¯ä¸€ä¸ªå†å²å¯¹è¯åˆ—è¡¨ï¼Œåˆ—è¡¨ä¸­æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªé•¿åº¦ä¸º2çš„åˆ—è¡¨ï¼Œç”±ä¸€é—®ä¸€ç­”ä¸¤ä¸ªå­—ç¬¦ä¸²ç»„æˆ
    url = "http://localhost:8000"
    payload = json.dumps({
        "query": query, 
        "history": history, 
        "max_length": max_length, 
        "top_p": top_p, 
        "temperature": temperature
    })
    headers = {'Content-Type': 'application/json'}

    full_response = requests.request("POST", url, headers=headers, data=payload)
    # è¿”å›å€¼response.json()åŒ…å« "response", "history", "status", "time", ä¾‹å¦‚ï¼š
    # {
    #     "response":"ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚",
    #     "history":[["ä½ å¥½","ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚"]],
    #     "status":200,
    #     "time":"2023-03-23 21:38:40"
    # }

    new_response = full_response.json()["response"]
    new_history = full_response.json()["history"]

    return new_response, new_history


if __name__ == '__main__':

    input = {
        'query': "123 + 123 + 123 + 123 = ï¼Ÿ",
        'history': [['123 * 4 = ?', '123 * 4 = 496']],
    }
    request, _ = gen_response(**input)
    print(request)
